# 转子部件脱落故障预测实验


2020/03/02   
1.在featureget.py中修改了有关ptp的函数，因为针对Series对象的ptp方法在pandas1.0.0版本后被移除。新的实现将Series对象转为numpy支持的array对象，调用其ptp方法。问题原因详见 https://pandas.pydata.org/docs/whatsnew/v1.0.0.html 页面GH21614部分。      
2.建议使用python3.7.x版本进行，否则本文件夹的train_nn.py可能不能正常运行。因截至目前 https://tensorflow.google.cn/install 中显示，目前tensorflow2.0仅支持到python3.7。另，在pylint下train_nn.py会报import错误，但实际上能够正常运行。   
3.使用较新的库版本试运行了一次，增加了一组运行基本无问题的库版本。

---

教程链接在phmlearn.com->转子部件脱落故障预测->四、实验->转子部件脱落故障预测实验
细节部分的内容参考转子部件脱落故障预测页面以及实验页面的详细说明

一、实验的准备以及数据观察

1、python3.x 以及代码中导入的库或包，视频中采用的是conda环境下python3.7.5/3.7.6进行实验；   
pandas 0.25.2/1.0.1   
scipy 1.3.1/1.4.1   
joblib 0.14.1   
tensorflow 2.0.0/2.1.0   
matplotlib 3.1.1/3.1.3   
sklearn 0.21.3/0.22.1   

2、在特定位置建立好单独的工程文件夹，视频中在E:\中建立experiment文件夹，并在文件夹下预先建立：
   code datacleaned datacsv dataset featureset model 六个文件夹，代码中包括的路径名称参照这些文件夹建立。

3、原始数据存放在dataset文件夹中，代码存放在code文件夹中

二、数据整合

在实验前，建议了解数据集的结构，数据集的结构比较复杂
理解实验任务非常重要，数据的整合、清洗以及模型选取都是依照实验任务以及本实验所采取的方案进行，如果实验方案改动，所有流程可能都有变化。
数据整合部分的代码也正是依照数据的基本情况进行数据处理
在code文件夹下建立datagena.py
由于数据较多，运行时间可能非常长，可以通过Now processing的进度查看
18个文件就是最终结果，data_fault和data_normal是之后步骤产生的文件，现在不用考虑

三、数据清洗

主要是依靠speed转速这一属性对数据的有效性进行筛查
刚才的代码中为了方便，直接将阈值设为0，即不对数据进行清洗，具体做实验时应根据对转速的观察结果，进行适当的清洗
输出文件保存在datacleaned文件夹中
分别是处理前的数据情况以及处理后的数据情况

四、训练集准备

重点在确定正样本和负样本的依据，二者分开存储主要是方便打标签

以上是数据处理的部分，数据处理主要是针对数据的基本情况，整理成模型需要的格式，以及根据工业场景中的实际情况判断数据是否需要清洗
本实验的数据处理部分时间需要相对较长
data_fault和data_normal这两个文件就是我们的训练集，负样本和正样本的数据文件

第一个视频中，运行数据处理相关的代码时需要的时间较长，因此在运行部分文件时只演示了运行过程中打印出的内容，然后使用ctrl+c停止了运行，
并不是代码运行只需要几分钟的时间，实际运行时，数据整合部分可能需要很长的时间。

五、特征提取

特征提取主要需要考虑实际场景中能够反映转子部件运行情况的特征。倍频特征是旋转机械常用的一类重要特征，在教程中频谱/阶次谱观察的部分有介绍。
实验手册中只给出了df_normal的提取示例，实际提取时还要对训练集故障样本和测试集进行相同形式的特征提取
特征提取的时间也比较长，这里也不实际运行

六、特征选择

这里只是使用了峰峰值以及倍频能量占比作为特征选择的结果，也可以采用机器学习常用的特征选择方法以及其他根据转子工作场景工作机理的筛选方法进行特征选择。

七、模型训练以及实验

这里只使用了默认参数对模型进行训练，实验手册中给出了lightgbm可参考的文档链接，文档中给出了训练超参数说明，可以根据说明对模型超参数进行调整，反复实验。

八、对比实验
教程链接在phmlearn.com->转子部件脱落故障预测->四、实验->转子部件脱落故障预测对比实验
knn的效果可能比较差，可能需要对特征进行归一化处理，或用其他特征等方法改进，或者调整模型参数，可以自己尝试
神经网络的输出是单输出，所以与其他两模型有区别
